{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# F1 Race Report Generator\n",
        "\n",
        "Two-agent system with memory:\n",
        "- **Agent 1**: Data Collection (FastF1)\n",
        "- **Agent 2**: Report Generation (Gemini)\n",
        "- **Memory**: Store and retrieve race reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q google-cloud-aiplatform google-adk fastf1 pandas python-dotenv nest_asyncio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Imports & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment configured\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Any\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "import fastf1\n",
        "import vertexai\n",
        "import nest_asyncio\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "\n",
        "# Configuration\n",
        "load_dotenv()\n",
        "PROJECT_ID = os.getenv('GCP_PROJECT_ID', 'gen-lang-client-0467867580')\n",
        "LOCATION = os.getenv('GCP_LOCATION', 'us-central1')\n",
        "MODEL_NAME = 'gemini-2.5-flash'\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "nest_asyncio.apply()\n",
        "fastf1.Cache.enable_cache('f1_cache')\n",
        "\n",
        "print(\"Environment configured\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Agent Engine Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using existing Agent Engine: projects/178353823233/locations/us-central1/reasoningEngines/349394008981635072\n",
            "Engine ID: 349394008981635072\n"
          ]
        }
      ],
      "source": [
        "# Initialize Vertex AI Agent Engine for Memory Bank\n",
        "client = vertexai.Client(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Try to get existing agent engine or create new one\n",
        "try:\n",
        "    # List existing agent engines\n",
        "    agent_engines = list(client.agent_engines.list())\n",
        "    if agent_engines:\n",
        "        agent_engine = agent_engines[0]\n",
        "        print(f\"Using existing Agent Engine: {agent_engine.api_resource.name}\")\n",
        "    else:\n",
        "        # Create new agent engine\n",
        "        agent_engine = client.agent_engines.create()\n",
        "        print(f\"Created new Agent Engine: {agent_engine.api_resource.name}\")\n",
        "    \n",
        "    agent_engine_id = agent_engine.api_resource.name.split(\"/\")[-1]\n",
        "    print(f\"Engine ID: {agent_engine_id}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing Agent Engine: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Memory Service (Vertex AI Memory Bank)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 4 report(s) from local backup\n",
            "Memory service initialized (Vertex AI Memory Bank + local backup)\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from google.adk.memory import VertexAiMemoryBankService\n",
        "\n",
        "class MemoryService:\n",
        "    \"\"\"Persistent storage for race reports using Vertex AI Memory Bank + local backup.\"\"\"\n",
        "    \n",
        "    def __init__(self, project: str, location: str, agent_engine_id: str, backup_file: str = \"f1_reports_backup.json\"):\n",
        "        self._service = VertexAiMemoryBankService(\n",
        "            project=project,\n",
        "            location=location,\n",
        "            agent_engine_id=agent_engine_id\n",
        "        )\n",
        "        self._cache = {}  # Local cache for quick access\n",
        "        self._backup_file = backup_file\n",
        "        self._load_from_backup()  # Load from local backup first\n",
        "    \n",
        "    def _load_from_backup(self):\n",
        "        \"\"\"Load reports from local JSON backup file.\"\"\"\n",
        "        try:\n",
        "            if os.path.exists(self._backup_file):\n",
        "                with open(self._backup_file, 'r', encoding='utf-8') as f:\n",
        "                    self._cache = json.load(f)\n",
        "                print(f\"Loaded {len(self._cache)} report(s) from local backup\")\n",
        "            else:\n",
        "                print(\"No local backup found, starting fresh\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading backup: {e}\")\n",
        "    \n",
        "    def _save_to_backup(self):\n",
        "        \"\"\"Save reports to local JSON backup file.\"\"\"\n",
        "        try:\n",
        "            with open(self._backup_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(self._cache, f, indent=2, ensure_ascii=False)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving backup: {e}\")\n",
        "    \n",
        "    def add_session_to_memory(self, race_id: str, report_data: Dict[str, Any]) -> None:\n",
        "        \"\"\"Store a race report in Memory Bank and local backup.\"\"\"\n",
        "        try:\n",
        "            timestamp = datetime.now().isoformat()\n",
        "            entry = {\n",
        "                \"data\": report_data,\n",
        "                \"timestamp\": timestamp\n",
        "            }\n",
        "            \n",
        "            # Store in local cache\n",
        "            self._cache[race_id] = entry\n",
        "            \n",
        "            # Save to local backup file immediately\n",
        "            self._save_to_backup()\n",
        "            \n",
        "            # Store in Memory Bank (async operation wrapped in sync)\n",
        "            loop = asyncio.get_event_loop()\n",
        "            if loop.is_running():\n",
        "                asyncio.ensure_future(self._async_add_session(race_id, entry))\n",
        "            else:\n",
        "                loop.run_until_complete(self._async_add_session(race_id, entry))\n",
        "        except Exception as e:\n",
        "            print(f\"Error storing in Memory Bank: {e}\")\n",
        "            raise\n",
        "    \n",
        "    async def _async_add_session(self, race_id: str, entry: Dict[str, Any]):\n",
        "        \"\"\"Async helper to add session to Memory Bank.\"\"\"\n",
        "        # Create a session object that Memory Bank expects\n",
        "        from google.adk.sessions import Session\n",
        "        session = Session(\n",
        "            session_id=race_id,\n",
        "            user_id=\"f1_report_system\",\n",
        "            metadata=entry\n",
        "        )\n",
        "        await self._service.add_session_to_memory(session)\n",
        "    \n",
        "    def _search_local_cache(self, query: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Search stored reports in local cache by race_id or GP name.\"\"\"\n",
        "        results = []\n",
        "        query_lower = query.lower()\n",
        "        \n",
        "        for race_id, entry in self._cache.items():\n",
        "            # Search in race_id and GP name\n",
        "            gp_name = entry['data'].get('race_data', {}).get('gp_info', {}).get('name', '')\n",
        "            if query_lower in race_id.lower() or query_lower in gp_name.lower():\n",
        "                results.append({\n",
        "                    \"race_id\": race_id,\n",
        "                    \"gp_name\": gp_name,\n",
        "                    \"timestamp\": entry['timestamp']\n",
        "                })\n",
        "        \n",
        "        return results\n",
        "\n",
        "    async def _async_search_memory_vertex(self, query: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Async helper to search Vertex AI Memory Bank and map results to local cache entries.\"\"\"\n",
        "        try:\n",
        "            # Search with required parameters\n",
        "            response = await self._service.search_memory(\n",
        "                query=query,\n",
        "                app_name=\"f1_report_system\",\n",
        "                user_id=\"f1_report_system\"\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Vertex AI Memory Bank search error: {e}\")\n",
        "            return []\n",
        "        \n",
        "        results = []\n",
        "        memories = getattr(response, \"memories\", None) or getattr(response, \"Memories\", None) or []\n",
        "        for mem in memories:\n",
        "            # Try to get a session_id / race_id from the memory result\n",
        "            race_id = getattr(mem, \"session_id\", None)\n",
        "            entry = None\n",
        "\n",
        "            # Some implementations may nest a Session object\n",
        "            if hasattr(mem, \"session\"):\n",
        "                session_obj = getattr(mem, \"session\")\n",
        "                if session_obj is not None:\n",
        "                    race_id = race_id or getattr(session_obj, \"session_id\", None)\n",
        "                    metadata = getattr(session_obj, \"metadata\", None)\n",
        "                    if isinstance(metadata, dict):\n",
        "                        entry = metadata\n",
        "\n",
        "            # Fallback: some implementations may expose metadata / data directly\n",
        "            if entry is None:\n",
        "                metadata = getattr(mem, \"metadata\", None)\n",
        "                if isinstance(metadata, dict):\n",
        "                    entry = metadata\n",
        "\n",
        "            if not race_id:\n",
        "                # Without a race_id we can't map cleanly; skip this memory\n",
        "                continue\n",
        "\n",
        "            # Prefer our local cache copy when available\n",
        "            if race_id in self._cache:\n",
        "                entry = self._cache[race_id]\n",
        "\n",
        "            if not entry:\n",
        "                continue\n",
        "\n",
        "            # Keep cache up to date if we learned this entry from Vertex\n",
        "            if race_id not in self._cache:\n",
        "                self._cache[race_id] = entry\n",
        "\n",
        "            gp_name = entry['data'].get('race_data', {}).get('gp_info', {}).get('name', '')\n",
        "            results.append({\n",
        "                \"race_id\": race_id,\n",
        "                \"gp_name\": gp_name,\n",
        "                \"timestamp\": entry['timestamp']\n",
        "            })\n",
        "        \n",
        "        return results\n",
        "\n",
        "    def search_memory(self, query: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Search stored reports, preferring Vertex AI Memory Bank and falling back to local cache.\"\"\"\n",
        "        # Try Vertex AI Memory Bank first\n",
        "        try:\n",
        "            try:\n",
        "                loop = asyncio.get_event_loop()\n",
        "            except RuntimeError:\n",
        "                loop = asyncio.new_event_loop()\n",
        "                asyncio.set_event_loop(loop)\n",
        "\n",
        "            vertex_results = loop.run_until_complete(self._async_search_memory_vertex(query))\n",
        "            if vertex_results:\n",
        "                return vertex_results\n",
        "        except Exception as e:\n",
        "            print(f\"Vertex search failed, using local cache: {e}\")\n",
        "        \n",
        "        # Fallback: local cache search (previous behavior)\n",
        "        return self._search_local_cache(query)\n",
        "    \n",
        "    def get_report(self, race_id: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Retrieve a specific report.\"\"\"\n",
        "        return self._cache.get(race_id)\n",
        "    \n",
        "    def list_all(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"List all stored reports.\"\"\"\n",
        "        return [{\n",
        "            \"race_id\": race_id,\n",
        "            \"gp_name\": entry['data'].get('race_data', {}).get('gp_info', {}).get('name', 'Unknown'),\n",
        "            \"timestamp\": entry['timestamp']\n",
        "        } for race_id, entry in self._cache.items()]\n",
        "\n",
        "# Initialize memory service with Vertex AI Memory Bank + local backup\n",
        "memory = MemoryService(\n",
        "    project=PROJECT_ID,\n",
        "    location=LOCATION,\n",
        "    agent_engine_id=agent_engine_id\n",
        ")\n",
        "print(\"Memory service initialized (Vertex AI Memory Bank + local backup)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calendar loaded: 24 races\n"
          ]
        }
      ],
      "source": [
        "# F1 Calendar (2024/2025 - compatible structure)\n",
        "F1_2025_CALENDAR = {\n",
        "    1: {\"name\": \"Bahrain Grand Prix\", \"circuit\": \"Bahrain International Circuit\"},\n",
        "    2: {\"name\": \"Saudi Arabian Grand Prix\", \"circuit\": \"Jeddah Corniche Circuit\"},\n",
        "    3: {\"name\": \"Australian Grand Prix\", \"circuit\": \"Albert Park Circuit\"},\n",
        "    4: {\"name\": \"Japanese Grand Prix\", \"circuit\": \"Suzuka International Racing Course\"},\n",
        "    5: {\"name\": \"Chinese Grand Prix\", \"circuit\": \"Shanghai International Circuit\"},\n",
        "    6: {\"name\": \"Miami Grand Prix\", \"circuit\": \"Miami International Autodrome\"},\n",
        "    7: {\"name\": \"Emilia Romagna Grand Prix\", \"circuit\": \"Autodromo Enzo e Dino Ferrari\"},\n",
        "    8: {\"name\": \"Monaco Grand Prix\", \"circuit\": \"Circuit de Monaco\"},\n",
        "    9: {\"name\": \"Spanish Grand Prix\", \"circuit\": \"Circuit de Barcelona-Catalunya\"},\n",
        "    10: {\"name\": \"Canadian Grand Prix\", \"circuit\": \"Circuit Gilles Villeneuve\"},\n",
        "    11: {\"name\": \"Austrian Grand Prix\", \"circuit\": \"Red Bull Ring\"},\n",
        "    12: {\"name\": \"British Grand Prix\", \"circuit\": \"Silverstone Circuit\"},\n",
        "    13: {\"name\": \"Belgian Grand Prix\", \"circuit\": \"Circuit de Spa-Francorchamps\"},\n",
        "    14: {\"name\": \"Hungarian Grand Prix\", \"circuit\": \"Hungaroring\"},\n",
        "    15: {\"name\": \"Dutch Grand Prix\", \"circuit\": \"Circuit Zandvoort\"},\n",
        "    16: {\"name\": \"Italian Grand Prix\", \"circuit\": \"Autodromo Nazionale di Monza\"},\n",
        "    17: {\"name\": \"Azerbaijan Grand Prix\", \"circuit\": \"Baku City Circuit\"},\n",
        "    18: {\"name\": \"Singapore Grand Prix\", \"circuit\": \"Marina Bay Street Circuit\"},\n",
        "    19: {\"name\": \"United States Grand Prix\", \"circuit\": \"Circuit of the Americas\"},\n",
        "    20: {\"name\": \"Mexico City Grand Prix\", \"circuit\": \"Autódromo Hermanos Rodríguez\"},\n",
        "    21: {\"name\": \"São Paulo Grand Prix\", \"circuit\": \"Autódromo José Carlos Pace\"},\n",
        "    22: {\"name\": \"Las Vegas Grand Prix\", \"circuit\": \"Las Vegas Street Circuit\"},\n",
        "    23: {\"name\": \"Qatar Grand Prix\", \"circuit\": \"Lusail International Circuit\"},\n",
        "    24: {\"name\": \"Abu Dhabi Grand Prix\", \"circuit\": \"Yas Marina Circuit\"}\n",
        "}\n",
        "\n",
        "print(f\"Calendar loaded: {len(F1_2025_CALENDAR)} races\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Agent 1: Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent 1 initialized\n"
          ]
        }
      ],
      "source": [
        "class DataCollectionAgent:\n",
        "    \"\"\"Validates input and collects F1 race data.\"\"\"\n",
        "    \n",
        "    def __init__(self, calendar: Dict[int, Dict[str, str]], year: int = 2025):\n",
        "        self.calendar = calendar\n",
        "        self.year = year\n",
        "    \n",
        "    def validate_input(self, user_input: str) -> Optional[int]:\n",
        "        \"\"\"Validate and convert user input to round number.\"\"\"\n",
        "        user_input = user_input.strip()\n",
        "        \n",
        "        # Try parsing as round number\n",
        "        try:\n",
        "            round_num = int(user_input)\n",
        "            return round_num if round_num in self.calendar else None\n",
        "        except ValueError:\n",
        "            pass\n",
        "        \n",
        "        # Try matching GP name\n",
        "        user_lower = user_input.lower()\n",
        "        for round_num, info in self.calendar.items():\n",
        "            if user_lower in info['name'].lower():\n",
        "                return round_num\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def collect_race_data(self, round_num: int, year: Optional[int] = None) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Collect comprehensive race data.\"\"\"\n",
        "        if year is None:\n",
        "            year = self.year\n",
        "            \n",
        "        try:\n",
        "            print(f\"Collecting data for Round {round_num} ({year})...\")\n",
        "            \n",
        "            # Get event and session\n",
        "            event = fastf1.get_event(year, round_num)\n",
        "            session = fastf1.get_session(year, round_num, \"R\")\n",
        "            session.load()\n",
        "            \n",
        "            results = session.results\n",
        "            \n",
        "            # Process results\n",
        "            drivers_results = []\n",
        "            for idx, row in results.iterrows():\n",
        "                # Try multiple position fields (fallback chain) with safe conversion\n",
        "                position = None\n",
        "                try:\n",
        "                    if pd.notna(row.get('Position')) and str(row.get('Position', '')).strip():\n",
        "                        position = int(row['Position'])\n",
        "                except (ValueError, TypeError):\n",
        "                    pass\n",
        "                \n",
        "                if position is None:\n",
        "                    try:\n",
        "                        if pd.notna(row.get('ClassifiedPosition')) and str(row.get('ClassifiedPosition', '')).strip():\n",
        "                            position = int(row['ClassifiedPosition'])\n",
        "                    except (ValueError, TypeError):\n",
        "                        pass\n",
        "                \n",
        "                if position is None and 'Status' in row and str(row['Status']) == 'Finished':\n",
        "                    # For finished drivers without position, use order in dataframe (usually sorted)\n",
        "                    position = len([d for d in drivers_results if d['position'] is not None]) + 1\n",
        "                \n",
        "                # Handle GridPosition safely (might be empty string or NaN)\n",
        "                grid_pos = None\n",
        "                try:\n",
        "                    if pd.notna(row['GridPosition']) and str(row['GridPosition']).strip():\n",
        "                        grid_pos = int(row['GridPosition'])\n",
        "                except (ValueError, TypeError):\n",
        "                    pass\n",
        "                \n",
        "                drivers_results.append({\n",
        "                    \"position\": position,\n",
        "                    \"full_name\": str(row['FullName']) if pd.notna(row['FullName']) else None,\n",
        "                    \"team\": str(row['TeamName']) if pd.notna(row['TeamName']) else None,\n",
        "                    \"grid_position\": grid_pos,\n",
        "                    \"time\": str(row['Time']) if pd.notna(row['Time']) else None,\n",
        "                    \"points\": float(row['Points']) if pd.notna(row['Points']) else 0.0,\n",
        "                })\n",
        "            \n",
        "            # If no positions were found, assign based on results order (FastF1 usually sorts by finish)\n",
        "            if all(r['position'] is None for r in drivers_results):\n",
        "                print(\"No position data from Ergast, using results order\")\n",
        "                for idx, driver in enumerate(drivers_results):\n",
        "                    driver['position'] = idx + 1\n",
        "            \n",
        "            # Get podium and key stats\n",
        "            podium = sorted([r for r in drivers_results if r['position'] in [1, 2, 3]], key=lambda x: x['position'])\n",
        "            \n",
        "            # Compile data\n",
        "            race_data = {\n",
        "                \"race_id\": f\"{year}_R{round_num}\",\n",
        "                \"year\": year,\n",
        "                \"round\": round_num,\n",
        "                \"gp_info\": {\n",
        "                    \"name\": event.EventName,\n",
        "                    \"country\": event.Country,\n",
        "                    \"circuit\": self.calendar[round_num]['circuit'],\n",
        "                },\n",
        "                \"podium\": podium,\n",
        "                \"final_results\": [r for r in drivers_results if r['position'] is not None]\n",
        "            }\n",
        "            \n",
        "            print(f\"Data collected: {event.EventName} ({year})\")\n",
        "            print(f\"Podium finishers: {len(podium)}\")\n",
        "            return race_data\n",
        "            \n",
        "        except Exception as e:\n",
        "            # Fallback to previous year if current year fails\n",
        "            if year >= 2024 and year == self.year:\n",
        "                print(f\"{year} data unavailable, trying {year-1}...\")\n",
        "                return self.collect_race_data(round_num, year=year-1)\n",
        "            print(f\"Error: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def run(self, user_input: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Main execution.\"\"\"\n",
        "        round_num = self.validate_input(user_input)\n",
        "        if not round_num:\n",
        "            print(f\"Invalid input: '{user_input}'\")\n",
        "            return None\n",
        "        return self.collect_race_data(round_num)\n",
        "\n",
        "agent1 = DataCollectionAgent(F1_2025_CALENDAR)\n",
        "print(\"Agent 1 initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Agent 2: Report Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent 2 initialized\n"
          ]
        }
      ],
      "source": [
        "class ReportGenerationAgent:\n",
        "    \"\"\"Generates social media reports from race data.\"\"\"\n",
        "    \n",
        "    def __init__(self, model_name: str = 'gemini-2.5-flash'):\n",
        "        self.model = GenerativeModel(model_name)\n",
        "    \n",
        "    def generate_report(self, race_data: Dict[str, Any]) -> Optional[str]:\n",
        "        \"\"\"Generate social media post.\"\"\"\n",
        "        try:\n",
        "            gp_info = race_data['gp_info']\n",
        "            podium = race_data['podium']\n",
        "            \n",
        "            # Validate podium data\n",
        "            if len(podium) < 3:\n",
        "                print(f\"Incomplete podium data: only {len(podium)} finisher(s)\")\n",
        "                return None\n",
        "            \n",
        "            print(f\"Generating report for {gp_info['name']}...\")\n",
        "            \n",
        "            prompt = f\"\"\"Create an Instagram post for this F1 race:\n",
        "\n",
        "RACE: {gp_info['name']} ({race_data['year']})\n",
        "CIRCUIT: {gp_info['circuit']}\n",
        "\n",
        "PODIUM:\n",
        "1st: {podium[0]['full_name']} ({podium[0]['team']}) - Started P{podium[0]['grid_position']}\n",
        "2nd: {podium[1]['full_name']} ({podium[1]['team']}) - Started P{podium[1]['grid_position']}\n",
        "3rd: {podium[2]['full_name']} ({podium[2]['team']}) - Started P{podium[2]['grid_position']}\n",
        "\n",
        "Write an engaging social media post that tells the race story and highlights the key moments. Don't generate images, just text.\"\"\"\n",
        "\n",
        "            response = self.model.generate_content(\n",
        "                prompt,\n",
        "                generation_config={\n",
        "                    \"max_output_tokens\": 2048,\n",
        "                    \"temperature\": 0.5,\n",
        "                }\n",
        "            )\n",
        "            \n",
        "            print(f\"Report generated ({len(response.text)} chars)\")\n",
        "            return response.text.strip()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def run(self, race_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Main execution.\"\"\"\n",
        "        if not race_data:\n",
        "            return None\n",
        "        \n",
        "        social_media_post = self.generate_report(race_data)\n",
        "        if not social_media_post:\n",
        "            return None\n",
        "        \n",
        "        return {\n",
        "            \"race_id\": race_data['race_id'],\n",
        "            \"race_data\": race_data,\n",
        "            \"social_media_post\": social_media_post,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "agent2 = ReportGenerationAgent(MODEL_NAME)\n",
        "print(\"Agent 2 initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Workflow: Generate & Store Reports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Workflow ready\n"
          ]
        }
      ],
      "source": [
        "def generate_f1_report(race_input: str) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"Complete workflow: collect data → generate report → store in memory.\"\"\"\n",
        "    \n",
        "    # 1. Collect race data\n",
        "    race_data = agent1.run(race_input)\n",
        "    if not race_data:\n",
        "        return None\n",
        "    \n",
        "    # 2. Generate report\n",
        "    full_report = agent2.run(race_data)\n",
        "    if not full_report:\n",
        "        return None\n",
        "    \n",
        "    # 3. Store in memory (INGEST)\n",
        "    memory.add_session_to_memory(full_report['race_id'], full_report)\n",
        "    \n",
        "    # Display result\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SOCIAL MEDIA POST\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\n{full_report['social_media_post']}\\n\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Stored as: {full_report['race_id']}\")\n",
        "    \n",
        "    return full_report\n",
        "\n",
        "print(\"Workflow ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Memory Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory operations ready\n"
          ]
        }
      ],
      "source": [
        "# Search memory (RETRIEVE)\n",
        "def search_reports(query: str):\n",
        "    \"\"\"Search stored reports.\"\"\"\n",
        "    results = memory.search_memory(query)\n",
        "    if results:\n",
        "        print(f\"Found {len(results)} report(s):\")\n",
        "        for r in results:\n",
        "            print(f\"  - {r['race_id']}: {r['gp_name']} ({r['timestamp']})\")\n",
        "    else:\n",
        "        print(f\"No reports found for '{query}'\")\n",
        "    return results\n",
        "\n",
        "# List all reports\n",
        "def list_reports():\n",
        "    \"\"\"List all stored reports.\"\"\"\n",
        "    reports = memory.list_all()\n",
        "    if reports:\n",
        "        print(f\"Stored reports ({len(reports)}):\")\n",
        "        for r in reports:\n",
        "            print(f\"  - {r['race_id']}: {r['gp_name']}\")\n",
        "    else:\n",
        "        print(\"No reports stored yet\")\n",
        "    return reports\n",
        "\n",
        "# Get specific report\n",
        "def get_report(race_id: str):\n",
        "    \"\"\"Retrieve a specific report.\"\"\"\n",
        "    report = memory.get_report(race_id)\n",
        "    if report:\n",
        "        print(f\"Retrieved: {race_id}\")\n",
        "        print(f\"GP: {report['data']['race_data']['gp_info']['name']}\")\n",
        "        print(f\"Stored: {report['timestamp']}\")\n",
        "        return report\n",
        "    else:\n",
        "        print(f\"Report '{race_id}' not found\")\n",
        "        return None\n",
        "\n",
        "print(\"Memory operations ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Search & Retrieve from Memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stored reports (4):\n",
            "  - 2025_R1: Australian Grand Prix\n",
            "  - 2025_R8: Monaco Grand Prix\n",
            "  - 2025_R11: Austrian Grand Prix\n",
            "  - 2025_R14: Hungarian Grand Prix\n",
            "No reports found for 'Bahrain'\n",
            "Retrieved: 2025_R1\n",
            "GP: Australian Grand Prix\n",
            "Stored: 2025-11-25T11:02:05.773953\n"
          ]
        }
      ],
      "source": [
        "# List all stored reports\n",
        "list_reports()\n",
        "\n",
        "# Search for specific reports\n",
        "search_reports(\"Bahrain\")\n",
        "\n",
        "# Retrieve a specific report\n",
        "report = get_report(\"2025_R1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 report(s):\n",
            "  - 2025_R1: Australian Grand Prix (2025-11-25T11:02:05.773953)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'race_id': '2025_R1',\n",
              "  'gp_name': 'Australian Grand Prix',\n",
              "  'timestamp': '2025-11-25T11:02:05.773953'}]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search_reports(\"Australian Grand Prix\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting data for Round 1 (2025)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "core           INFO \tLoading data for Australian Grand Prix - Race [v3.4.5]\n",
            "req            INFO \tUsing cached data for session_info\n",
            "req            INFO \tUsing cached data for driver_info\n",
            "logger      WARNING \tFailed to load result data from Ergast!\n",
            "core        WARNING \tNo result data for this session available on Ergast! (This is expected for recent sessions)\n",
            "req            INFO \tUsing cached data for session_status_data\n",
            "req            INFO \tUsing cached data for lap_count\n",
            "req            INFO \tUsing cached data for track_status_data\n",
            "req            INFO \tUsing cached data for _extended_timing_data\n",
            "req            INFO \tUsing cached data for timing_app_data\n",
            "core           INFO \tProcessing timing data...\n",
            "logger      WARNING \tFailed to add first lap time from Ergast!\n",
            "req            INFO \tUsing cached data for car_data\n",
            "req            INFO \tUsing cached data for position_data\n",
            "req            INFO \tUsing cached data for weather_data\n",
            "req            INFO \tUsing cached data for race_control_messages\n",
            "core           INFO \tFinished loading data for 20 drivers: ['4', '81', '1', '63', '22', '23', '16', '44', '10', '55', '6', '14', '18', '7', '5', '12', '27', '30', '31', '87']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No position data from Ergast, using results order\n",
            "Data collected: Australian Grand Prix (2025)\n",
            "Podium finishers: 3\n",
            "Generating report for Australian Grand Prix...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Interactive mode\u001b[39;00m\n\u001b[32m      2\u001b[39m race_input = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEnter race (round number or GP name): \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m report = \u001b[43mgenerate_f1_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrace_input\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mgenerate_f1_report\u001b[39m\u001b[34m(race_input)\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 2. Generate report\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m full_report = \u001b[43magent2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrace_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m full_report:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mReportGenerationAgent.run\u001b[39m\u001b[34m(self, race_data)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m race_data:\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m social_media_post = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrace_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m social_media_post:\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mReportGenerationAgent.generate_report\u001b[39m\u001b[34m(self, race_data)\u001b[39m\n\u001b[32m     18\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating report for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgp_info[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m             prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mCreate an Instagram post for this F1 race:\u001b[39m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[33mRACE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgp_info[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrace_data[\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m \u001b[33mWrite an engaging social media post that tells the race story and highlights the key moments. Don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt generate images, just text.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m             response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m                \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReport generated (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(response.text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chars)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m response.text.strip()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\vertexai\\generative_models\\_generative_models.py:710\u001b[39m, in \u001b[36m_GenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[39m\n\u001b[32m    701\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_content_streaming(\n\u001b[32m    702\u001b[39m         contents=contents,\n\u001b[32m    703\u001b[39m         generation_config=generation_config,\n\u001b[32m   (...)\u001b[39m\u001b[32m    707\u001b[39m         labels=labels,\n\u001b[32m    708\u001b[39m     )\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m710\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\vertexai\\generative_models\\_generative_models.py:833\u001b[39m, in \u001b[36m_GenerativeModel._generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[39m\n\u001b[32m    806\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[32m    807\u001b[39m \n\u001b[32m    808\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m \u001b[33;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[32m    824\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    825\u001b[39m request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m    826\u001b[39m     contents=contents,\n\u001b[32m    827\u001b[39m     generation_config=generation_config,\n\u001b[32m   (...)\u001b[39m\u001b[32m    831\u001b[39m     labels=labels,\n\u001b[32m    832\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m gapic_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prediction_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_response(gapic_response)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\client.py:2300\u001b[39m, in \u001b[36mPredictionServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m   2297\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m   2299\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2300\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2302\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2304\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2305\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2307\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m   2308\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\api_core\\grpc_helpers.py:75\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(callable_)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34merror_remapped_callable\u001b[39m(*args, **kwargs):\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\grpc\\_interceptor.py:276\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    268\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    269\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     response, ignored_call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\grpc\\_interceptor.py:328\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m    326\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys.exc_info()[\u001b[32m2\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interceptor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m call.result(), call\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\transports\\grpc.py:83\u001b[39m, in \u001b[36m_LoggingClientInterceptor.intercept_unary_unary\u001b[39m\u001b[34m(self, continuation, client_call_details, request)\u001b[39m\n\u001b[32m     69\u001b[39m     grpc_request = {\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpayload\u001b[39m\u001b[33m\"\u001b[39m: request_payload,\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrequestMethod\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgrpc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[32m     73\u001b[39m     }\n\u001b[32m     74\u001b[39m     _LOGGER.debug(\n\u001b[32m     75\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details.method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     76\u001b[39m         extra={\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m         },\n\u001b[32m     82\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m response = \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[32m     85\u001b[39m     response_metadata = response.trailing_metadata()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\grpc\\_interceptor.py:314\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[39m\u001b[34m(new_details, request)\u001b[39m\n\u001b[32m    305\u001b[39m (\n\u001b[32m    306\u001b[39m     new_method,\n\u001b[32m    307\u001b[39m     new_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m    311\u001b[39m     new_compression,\n\u001b[32m    312\u001b[39m ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     response, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\grpc\\_channel.py:1177\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1168\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwith_call\u001b[39m(\n\u001b[32m   1169\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1170\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1175\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1176\u001b[39m ) -> Tuple[Any, grpc.Call]:\n\u001b[32m-> \u001b[39m\u001b[32m1177\u001b[39m     state, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1180\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\grpc\\_channel.py:1150\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._blocking\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1133\u001b[39m state.target = _common.decode(\u001b[38;5;28mself\u001b[39m._target)\n\u001b[32m   1134\u001b[39m call = \u001b[38;5;28mself\u001b[39m._channel.segregated_call(\n\u001b[32m   1135\u001b[39m     cygrpc.PropagationConstants.GRPC_PROPAGATE_DEFAULTS,\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28mself\u001b[39m._method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1148\u001b[39m     \u001b[38;5;28mself\u001b[39m._registered_call_handle,\n\u001b[32m   1149\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m event = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1151\u001b[39m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m._response_deserializer)\n\u001b[32m   1152\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
            "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[39m, in \u001b[36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:97\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:80\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._internal_latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Interactive mode\n",
        "race_input = input(\"Enter race (round number or GP name): \")\n",
        "report = generate_f1_report(race_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stored reports (6):\n",
            "  - 2025_R1: Australian Grand Prix\n",
            "  - 2025_R8: Monaco Grand Prix\n",
            "  - 2025_R11: Austrian Grand Prix\n",
            "  - 2025_R14: Hungarian Grand Prix\n",
            "  - 2025_R21: São Paulo Grand Prix\n",
            "  - 2025_R19: United States Grand Prix\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'race_id': '2025_R1',\n",
              "  'gp_name': 'Australian Grand Prix',\n",
              "  'timestamp': '2025-11-25T11:02:05.773953'},\n",
              " {'race_id': '2025_R8',\n",
              "  'gp_name': 'Monaco Grand Prix',\n",
              "  'timestamp': '2025-11-25T09:27:51.198281'},\n",
              " {'race_id': '2025_R11',\n",
              "  'gp_name': 'Austrian Grand Prix',\n",
              "  'timestamp': '2025-11-25T11:09:32.423574'},\n",
              " {'race_id': '2025_R14',\n",
              "  'gp_name': 'Hungarian Grand Prix',\n",
              "  'timestamp': '2025-11-25T11:40:26.495634'},\n",
              " {'race_id': '2025_R21',\n",
              "  'gp_name': 'São Paulo Grand Prix',\n",
              "  'timestamp': '2025-11-25T12:17:37.296342'},\n",
              " {'race_id': '2025_R19',\n",
              "  'gp_name': 'United States Grand Prix',\n",
              "  'timestamp': '2025-11-25T12:21:21.690172'}]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_reports()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
