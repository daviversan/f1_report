{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# F1 Race Report Generator\n",
        "\n",
        "Two-agent system with memory:\n",
        "- **Agent 1**: Data Collection (FastF1)\n",
        "- **Agent 2**: Report Generation (Gemini)\n",
        "- **Memory**: Store and retrieve race reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q google-cloud-aiplatform google-adk fastf1 pandas python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Imports & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Environment configured\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Any\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "import fastf1\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "\n",
        "# Configuration\n",
        "load_dotenv()\n",
        "PROJECT_ID = os.getenv('GCP_PROJECT_ID', 'gen-lang-client-0467867580')\n",
        "LOCATION = os.getenv('GCP_LOCATION', 'us-central1')\n",
        "MODEL_NAME = 'gemini-2.5-flash'\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "fastf1.Cache.enable_cache('f1_cache')\n",
        "\n",
        "print(\"‚úÖ Environment configured\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Agent Engine Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Using existing Agent Engine: projects/178353823233/locations/us-central1/reasoningEngines/349394008981635072\n",
            "   Engine ID: 349394008981635072\n"
          ]
        }
      ],
      "source": [
        "# Initialize Vertex AI Agent Engine for Memory Bank\n",
        "client = vertexai.Client(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Try to get existing agent engine or create new one\n",
        "try:\n",
        "    # List existing agent engines\n",
        "    agent_engines = list(client.agent_engines.list())\n",
        "    if agent_engines:\n",
        "        agent_engine = agent_engines[0]\n",
        "        print(f\"‚úÖ Using existing Agent Engine: {agent_engine.api_resource.name}\")\n",
        "    else:\n",
        "        # Create new agent engine\n",
        "        agent_engine = client.agent_engines.create()\n",
        "        print(f\"‚úÖ Created new Agent Engine: {agent_engine.api_resource.name}\")\n",
        "    \n",
        "    agent_engine_id = agent_engine.api_resource.name.split(\"/\")[-1]\n",
        "    print(f\"   Engine ID: {agent_engine_id}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing Agent Engine: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Memory Service (Vertex AI Memory Bank)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 2 report(s) from local backup\n",
            "Memory service initialized (Vertex AI Memory Bank + local backup)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory Bank sync not available - using local cache only\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from google.adk.memory import VertexAiMemoryBankService\n",
        "\n",
        "class MemoryService:\n",
        "    \"\"\"Persistent storage for race reports using Vertex AI Memory Bank + local backup.\"\"\"\n",
        "    \n",
        "    def __init__(self, project: str, location: str, agent_engine_id: str, backup_file: str = \"f1_reports_backup.json\"):\n",
        "        self._service = VertexAiMemoryBankService(\n",
        "            project=project,\n",
        "            location=location,\n",
        "            agent_engine_id=agent_engine_id\n",
        "        )\n",
        "        self._cache = {}  # Local cache for quick access\n",
        "        self._backup_file = backup_file\n",
        "        self._load_from_backup()  # Load from local backup first\n",
        "        self._sync_cache()  # Then sync with Memory Bank\n",
        "    \n",
        "    def _load_from_backup(self):\n",
        "        \"\"\"Load reports from local JSON backup file.\"\"\"\n",
        "        try:\n",
        "            if os.path.exists(self._backup_file):\n",
        "                with open(self._backup_file, 'r', encoding='utf-8') as f:\n",
        "                    self._cache = json.load(f)\n",
        "                print(f\"Loaded {len(self._cache)} report(s) from local backup\")\n",
        "            else:\n",
        "                print(\"‚ÑπNo local backup found, starting fresh\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading backup: {e}\")\n",
        "    \n",
        "    def _save_to_backup(self):\n",
        "        \"\"\"Save reports to local JSON backup file.\"\"\"\n",
        "        try:\n",
        "            with open(self._backup_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(self._cache, f, indent=2, ensure_ascii=False)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving backup: {e}\")\n",
        "    \n",
        "    def _sync_cache(self):\n",
        "        \"\"\"Sync local cache with Memory Bank.\"\"\"\n",
        "        try:\n",
        "            # Get all memories from Memory Bank\n",
        "            loop = asyncio.get_event_loop()\n",
        "            if loop.is_running():\n",
        "                # If loop is running, schedule task\n",
        "                asyncio.ensure_future(self._async_sync_cache())\n",
        "            else:\n",
        "                # Run in new event loop\n",
        "                loop.run_until_complete(self._async_sync_cache())\n",
        "        except Exception as e:\n",
        "            print(f\"Cache sync warning: {e}\")\n",
        "    \n",
        "    async def _async_sync_cache(self):\n",
        "        \"\"\"Async cache sync helper - retrieve all sessions from Memory Bank.\"\"\"\n",
        "        try:\n",
        "            # Use the memory bank service to retrieve all stored sessions\n",
        "            from google.adk.sessions import Session\n",
        "            \n",
        "            # Since Memory Bank doesn't have a direct \"list all\" method,\n",
        "            # we'll need to query it. Let's try to retrieve sessions by querying\n",
        "            # with a broad search that matches our stored data\n",
        "            \n",
        "            # Alternative: Use the underlying storage to list sessions\n",
        "            # The Memory Bank service stores sessions that we can retrieve\n",
        "            sessions = await self._service.get_sessions(user_id=\"f1_report_system\")\n",
        "            \n",
        "            if sessions:\n",
        "                for session in sessions:\n",
        "                    if hasattr(session, 'session_id') and hasattr(session, 'metadata'):\n",
        "                        race_id = session.session_id\n",
        "                        entry = session.metadata\n",
        "                        if entry and isinstance(entry, dict):\n",
        "                            self._cache[race_id] = entry\n",
        "                \n",
        "                print(f\"Synced {len(self._cache)} report(s) from Memory Bank\")\n",
        "        except AttributeError:\n",
        "            # If get_sessions doesn't exist, try alternative approach\n",
        "            print(\"Memory Bank sync not available - using local cache only\")\n",
        "        except Exception as e:\n",
        "            print(f\"Async cache sync error: {e}\")\n",
        "    \n",
        "    def add_session_to_memory(self, race_id: str, report_data: Dict[str, Any]) -> None:\n",
        "        \"\"\"Store a race report in Memory Bank and local backup.\"\"\"\n",
        "        try:\n",
        "            timestamp = datetime.now().isoformat()\n",
        "            entry = {\n",
        "                \"data\": report_data,\n",
        "                \"timestamp\": timestamp\n",
        "            }\n",
        "            \n",
        "            # Store in local cache\n",
        "            self._cache[race_id] = entry\n",
        "            \n",
        "            # Save to local backup file immediately\n",
        "            self._save_to_backup()\n",
        "            \n",
        "            # Store in Memory Bank (async operation wrapped in sync)\n",
        "            loop = asyncio.get_event_loop()\n",
        "            if loop.is_running():\n",
        "                asyncio.ensure_future(self._async_add_session(race_id, entry))\n",
        "            else:\n",
        "                loop.run_until_complete(self._async_add_session(race_id, entry))\n",
        "        except Exception as e:\n",
        "            print(f\"Error storing in Memory Bank: {e}\")\n",
        "            raise\n",
        "    \n",
        "    async def _async_add_session(self, race_id: str, entry: Dict[str, Any]):\n",
        "        \"\"\"Async helper to add session to Memory Bank.\"\"\"\n",
        "        # Create a session object that Memory Bank expects\n",
        "        from google.adk.sessions import Session\n",
        "        session = Session(\n",
        "            session_id=race_id,\n",
        "            user_id=\"f1_report_system\",\n",
        "            metadata=entry\n",
        "        )\n",
        "        await self._service.add_session_to_memory(session)\n",
        "    \n",
        "    def search_memory(self, query: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Search stored reports by race_id or GP name.\"\"\"\n",
        "        results = []\n",
        "        query_lower = query.lower()\n",
        "        \n",
        "        for race_id, entry in self._cache.items():\n",
        "            # Search in race_id and GP name\n",
        "            gp_name = entry['data'].get('race_data', {}).get('gp_info', {}).get('name', '')\n",
        "            if query_lower in race_id.lower() or query_lower in gp_name.lower():\n",
        "                results.append({\n",
        "                    \"race_id\": race_id,\n",
        "                    \"gp_name\": gp_name,\n",
        "                    \"timestamp\": entry['timestamp']\n",
        "                })\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def get_report(self, race_id: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Retrieve a specific report.\"\"\"\n",
        "        return self._cache.get(race_id)\n",
        "    \n",
        "    def list_all(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"List all stored reports.\"\"\"\n",
        "        return [{\n",
        "            \"race_id\": race_id,\n",
        "            \"gp_name\": entry['data'].get('race_data', {}).get('gp_info', {}).get('name', 'Unknown'),\n",
        "            \"timestamp\": entry['timestamp']\n",
        "        } for race_id, entry in self._cache.items()]\n",
        "\n",
        "# Initialize memory service with Vertex AI Memory Bank + local backup\n",
        "memory = MemoryService(\n",
        "    project=PROJECT_ID,\n",
        "    location=LOCATION,\n",
        "    agent_engine_id=agent_engine_id\n",
        ")\n",
        "print(\"Memory service initialized (Vertex AI Memory Bank + local backup)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Calendar loaded: 24 races\n"
          ]
        }
      ],
      "source": [
        "# F1 Calendar (2024/2025 - compatible structure)\n",
        "F1_2025_CALENDAR = {\n",
        "    1: {\"name\": \"Bahrain Grand Prix\", \"circuit\": \"Bahrain International Circuit\"},\n",
        "    2: {\"name\": \"Saudi Arabian Grand Prix\", \"circuit\": \"Jeddah Corniche Circuit\"},\n",
        "    3: {\"name\": \"Australian Grand Prix\", \"circuit\": \"Albert Park Circuit\"},\n",
        "    4: {\"name\": \"Japanese Grand Prix\", \"circuit\": \"Suzuka International Racing Course\"},\n",
        "    5: {\"name\": \"Chinese Grand Prix\", \"circuit\": \"Shanghai International Circuit\"},\n",
        "    6: {\"name\": \"Miami Grand Prix\", \"circuit\": \"Miami International Autodrome\"},\n",
        "    7: {\"name\": \"Emilia Romagna Grand Prix\", \"circuit\": \"Autodromo Enzo e Dino Ferrari\"},\n",
        "    8: {\"name\": \"Monaco Grand Prix\", \"circuit\": \"Circuit de Monaco\"},\n",
        "    9: {\"name\": \"Spanish Grand Prix\", \"circuit\": \"Circuit de Barcelona-Catalunya\"},\n",
        "    10: {\"name\": \"Canadian Grand Prix\", \"circuit\": \"Circuit Gilles Villeneuve\"},\n",
        "    11: {\"name\": \"Austrian Grand Prix\", \"circuit\": \"Red Bull Ring\"},\n",
        "    12: {\"name\": \"British Grand Prix\", \"circuit\": \"Silverstone Circuit\"},\n",
        "    13: {\"name\": \"Belgian Grand Prix\", \"circuit\": \"Circuit de Spa-Francorchamps\"},\n",
        "    14: {\"name\": \"Hungarian Grand Prix\", \"circuit\": \"Hungaroring\"},\n",
        "    15: {\"name\": \"Dutch Grand Prix\", \"circuit\": \"Circuit Zandvoort\"},\n",
        "    16: {\"name\": \"Italian Grand Prix\", \"circuit\": \"Autodromo Nazionale di Monza\"},\n",
        "    17: {\"name\": \"Azerbaijan Grand Prix\", \"circuit\": \"Baku City Circuit\"},\n",
        "    18: {\"name\": \"Singapore Grand Prix\", \"circuit\": \"Marina Bay Street Circuit\"},\n",
        "    19: {\"name\": \"United States Grand Prix\", \"circuit\": \"Circuit of the Americas\"},\n",
        "    20: {\"name\": \"Mexico City Grand Prix\", \"circuit\": \"Aut√≥dromo Hermanos Rodr√≠guez\"},\n",
        "    21: {\"name\": \"S√£o Paulo Grand Prix\", \"circuit\": \"Aut√≥dromo Jos√© Carlos Pace\"},\n",
        "    22: {\"name\": \"Las Vegas Grand Prix\", \"circuit\": \"Las Vegas Street Circuit\"},\n",
        "    23: {\"name\": \"Qatar Grand Prix\", \"circuit\": \"Lusail International Circuit\"},\n",
        "    24: {\"name\": \"Abu Dhabi Grand Prix\", \"circuit\": \"Yas Marina Circuit\"}\n",
        "}\n",
        "\n",
        "print(f\"‚úÖ Calendar loaded: {len(F1_2025_CALENDAR)} races\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Agent 1: Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Agent 1 initialized\n"
          ]
        }
      ],
      "source": [
        "class DataCollectionAgent:\n",
        "    \"\"\"Validates input and collects F1 race data.\"\"\"\n",
        "    \n",
        "    def __init__(self, calendar: Dict[int, Dict[str, str]], year: int = 2025):\n",
        "        self.calendar = calendar\n",
        "        self.year = year\n",
        "    \n",
        "    def validate_input(self, user_input: str) -> Optional[int]:\n",
        "        \"\"\"Validate and convert user input to round number.\"\"\"\n",
        "        user_input = user_input.strip()\n",
        "        \n",
        "        # Try parsing as round number\n",
        "        try:\n",
        "            round_num = int(user_input)\n",
        "            return round_num if round_num in self.calendar else None\n",
        "        except ValueError:\n",
        "            pass\n",
        "        \n",
        "        # Try matching GP name\n",
        "        user_lower = user_input.lower()\n",
        "        for round_num, info in self.calendar.items():\n",
        "            if user_lower in info['name'].lower():\n",
        "                return round_num\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def collect_race_data(self, round_num: int, year: Optional[int] = None) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Collect comprehensive race data.\"\"\"\n",
        "        if year is None:\n",
        "            year = self.year\n",
        "            \n",
        "        try:\n",
        "            print(f\"üîç Collecting data for Round {round_num} ({year})...\")\n",
        "            \n",
        "            # Get event and session\n",
        "            event = fastf1.get_event(year, round_num)\n",
        "            session = fastf1.get_session(year, round_num, \"R\")\n",
        "            session.load()\n",
        "            \n",
        "            results = session.results\n",
        "            \n",
        "            # Process results\n",
        "            drivers_results = []\n",
        "            for idx, row in results.iterrows():\n",
        "                # Try multiple position fields (fallback chain) with safe conversion\n",
        "                position = None\n",
        "                try:\n",
        "                    if pd.notna(row.get('Position')) and str(row.get('Position', '')).strip():\n",
        "                        position = int(row['Position'])\n",
        "                except (ValueError, TypeError):\n",
        "                    pass\n",
        "                \n",
        "                if position is None:\n",
        "                    try:\n",
        "                        if pd.notna(row.get('ClassifiedPosition')) and str(row.get('ClassifiedPosition', '')).strip():\n",
        "                            position = int(row['ClassifiedPosition'])\n",
        "                    except (ValueError, TypeError):\n",
        "                        pass\n",
        "                \n",
        "                if position is None and 'Status' in row and str(row['Status']) == 'Finished':\n",
        "                    # For finished drivers without position, use order in dataframe (usually sorted)\n",
        "                    position = len([d for d in drivers_results if d['position'] is not None]) + 1\n",
        "                \n",
        "                # Handle GridPosition safely (might be empty string or NaN)\n",
        "                grid_pos = None\n",
        "                try:\n",
        "                    if pd.notna(row['GridPosition']) and str(row['GridPosition']).strip():\n",
        "                        grid_pos = int(row['GridPosition'])\n",
        "                except (ValueError, TypeError):\n",
        "                    pass\n",
        "                \n",
        "                drivers_results.append({\n",
        "                    \"position\": position,\n",
        "                    \"full_name\": str(row['FullName']) if pd.notna(row['FullName']) else None,\n",
        "                    \"team\": str(row['TeamName']) if pd.notna(row['TeamName']) else None,\n",
        "                    \"grid_position\": grid_pos,\n",
        "                    \"time\": str(row['Time']) if pd.notna(row['Time']) else None,\n",
        "                    \"points\": float(row['Points']) if pd.notna(row['Points']) else 0.0,\n",
        "                })\n",
        "            \n",
        "            # If no positions were found, assign based on results order (FastF1 usually sorts by finish)\n",
        "            if all(r['position'] is None for r in drivers_results):\n",
        "                print(\"   ‚ÑπNo position data from Ergast, using results order\")\n",
        "                for idx, driver in enumerate(drivers_results):\n",
        "                    driver['position'] = idx + 1\n",
        "            \n",
        "            # Get podium and key stats\n",
        "            podium = sorted([r for r in drivers_results if r['position'] in [1, 2, 3]], key=lambda x: x['position'])\n",
        "            \n",
        "            # Compile data\n",
        "            race_data = {\n",
        "                \"race_id\": f\"{year}_R{round_num}\",\n",
        "                \"year\": year,\n",
        "                \"round\": round_num,\n",
        "                \"gp_info\": {\n",
        "                    \"name\": event.EventName,\n",
        "                    \"country\": event.Country,\n",
        "                    \"circuit\": self.calendar[round_num]['circuit'],\n",
        "                },\n",
        "                \"podium\": podium,\n",
        "                \"final_results\": [r for r in drivers_results if r['position'] is not None]\n",
        "            }\n",
        "            \n",
        "            print(f\"‚úÖ Data collected: {event.EventName} ({year})\")\n",
        "            print(f\"   Podium finishers: {len(podium)}\")\n",
        "            return race_data\n",
        "            \n",
        "        except Exception as e:\n",
        "            # Fallback to previous year if current year fails\n",
        "            if year >= 2024 and year == self.year:\n",
        "                print(f\"‚ö†Ô∏è {year} data unavailable, trying {year-1}...\")\n",
        "                return self.collect_race_data(round_num, year=year-1)\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def run(self, user_input: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Main execution.\"\"\"\n",
        "        round_num = self.validate_input(user_input)\n",
        "        if not round_num:\n",
        "            print(f\"‚ùå Invalid input: '{user_input}'\")\n",
        "            return None\n",
        "        return self.collect_race_data(round_num)\n",
        "\n",
        "agent1 = DataCollectionAgent(F1_2025_CALENDAR)\n",
        "print(\"‚úÖ Agent 1 initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Agent 2: Report Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Agent 2 initialized\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Inteli\\AppData\\Roaming\\Python\\Python313\\site-packages\\vertexai\\generative_models\\_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        }
      ],
      "source": [
        "class ReportGenerationAgent:\n",
        "    \"\"\"Generates social media reports from race data.\"\"\"\n",
        "    \n",
        "    def __init__(self, model_name: str = 'gemini-2.5-flash'):\n",
        "        self.model = GenerativeModel(model_name)\n",
        "    \n",
        "    def generate_report(self, race_data: Dict[str, Any]) -> Optional[str]:\n",
        "        \"\"\"Generate social media post.\"\"\"\n",
        "        try:\n",
        "            gp_info = race_data['gp_info']\n",
        "            podium = race_data['podium']\n",
        "            \n",
        "            # Validate podium data\n",
        "            if len(podium) < 3:\n",
        "                print(f\"‚ùå Incomplete podium data: only {len(podium)} finisher(s)\")\n",
        "                return None\n",
        "            \n",
        "            print(f\"‚úçÔ∏è Generating report for {gp_info['name']}...\")\n",
        "            \n",
        "            prompt = f\"\"\"Create an Instagram post for this F1 race:\n",
        "\n",
        "RACE: {gp_info['name']} ({race_data['year']})\n",
        "CIRCUIT: {gp_info['circuit']}\n",
        "\n",
        "PODIUM:\n",
        "1st: {podium[0]['full_name']} ({podium[0]['team']}) - Started P{podium[0]['grid_position']}\n",
        "2nd: {podium[1]['full_name']} ({podium[1]['team']}) - Started P{podium[1]['grid_position']}\n",
        "3rd: {podium[2]['full_name']} ({podium[2]['team']}) - Started P{podium[2]['grid_position']}\n",
        "\n",
        "Write an engaging 200-250 word post that tells the race story and highlights the key moments. Don't generate images, just text.\"\"\"\n",
        "\n",
        "            response = self.model.generate_content(\n",
        "                prompt,\n",
        "                generation_config={\n",
        "                    \"max_output_tokens\": 2048,\n",
        "                    \"temperature\": 0.5,\n",
        "                }\n",
        "            )\n",
        "            \n",
        "            print(f\"‚úÖ Report generated ({len(response.text)} chars)\")\n",
        "            return response.text.strip()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def run(self, race_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Main execution.\"\"\"\n",
        "        if not race_data:\n",
        "            return None\n",
        "        \n",
        "        social_media_post = self.generate_report(race_data)\n",
        "        if not social_media_post:\n",
        "            return None\n",
        "        \n",
        "        return {\n",
        "            \"race_id\": race_data['race_id'],\n",
        "            \"race_data\": race_data,\n",
        "            \"social_media_post\": social_media_post,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "agent2 = ReportGenerationAgent(MODEL_NAME)\n",
        "print(\"‚úÖ Agent 2 initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Workflow: Generate & Store Reports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Workflow ready\n"
          ]
        }
      ],
      "source": [
        "def generate_f1_report(race_input: str) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"Complete workflow: collect data ‚Üí generate report ‚Üí store in memory.\"\"\"\n",
        "    \n",
        "    # 1. Collect race data\n",
        "    race_data = agent1.run(race_input)\n",
        "    if not race_data:\n",
        "        return None\n",
        "    \n",
        "    # 2. Generate report\n",
        "    full_report = agent2.run(race_data)\n",
        "    if not full_report:\n",
        "        return None\n",
        "    \n",
        "    # 3. Store in memory (INGEST)\n",
        "    memory.add_session_to_memory(full_report['race_id'], full_report)\n",
        "    \n",
        "    # Display result\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üì± SOCIAL MEDIA POST\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\n{full_report['social_media_post']}\\n\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"üíæ Stored as: {full_report['race_id']}\")\n",
        "    \n",
        "    return full_report\n",
        "\n",
        "print(\"‚úÖ Workflow ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Memory Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Memory operations ready\n"
          ]
        }
      ],
      "source": [
        "# Search memory (RETRIEVE)\n",
        "def search_reports(query: str):\n",
        "    \"\"\"Search stored reports.\"\"\"\n",
        "    results = memory.search_memory(query)\n",
        "    if results:\n",
        "        print(f\"üîç Found {len(results)} report(s):\")\n",
        "        for r in results:\n",
        "            print(f\"  ‚Ä¢ {r['race_id']}: {r['gp_name']} ({r['timestamp']})\")\n",
        "    else:\n",
        "        print(f\"‚ùå No reports found for '{query}'\")\n",
        "    return results\n",
        "\n",
        "# List all reports\n",
        "def list_reports():\n",
        "    \"\"\"List all stored reports.\"\"\"\n",
        "    reports = memory.list_all()\n",
        "    if reports:\n",
        "        print(f\"üìã Stored reports ({len(reports)}):\")\n",
        "        for r in reports:\n",
        "            print(f\"  ‚Ä¢ {r['race_id']}: {r['gp_name']}\")\n",
        "    else:\n",
        "        print(\"üìã No reports stored yet\")\n",
        "    return reports\n",
        "\n",
        "# Get specific report\n",
        "def get_report(race_id: str):\n",
        "    \"\"\"Retrieve a specific report.\"\"\"\n",
        "    report = memory.get_report(race_id)\n",
        "    if report:\n",
        "        print(f\"‚úÖ Retrieved: {race_id}\")\n",
        "        print(f\"   GP: {report['data']['race_data']['gp_info']['name']}\")\n",
        "        print(f\"   Stored: {report['timestamp']}\")\n",
        "        return report\n",
        "    else:\n",
        "        print(f\"‚ùå Report '{race_id}' not found\")\n",
        "        return None\n",
        "\n",
        "print(\"‚úÖ Memory operations ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Example Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate a report (try with different races)\n",
        "report = generate_f1_report(\"Bahrain\")\n",
        "\n",
        "# Or use round number\n",
        "# report = generate_f1_report(\"1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Search & Retrieve from Memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all stored reports\n",
        "list_reports()\n",
        "\n",
        "# Search for specific reports\n",
        "search_reports(\"Bahrain\")\n",
        "\n",
        "# Retrieve a specific report\n",
        "report = get_report(\"2025_R1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive mode\n",
        "race_input = input(\"Enter race (round number or GP name): \")\n",
        "report = generate_f1_report(race_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Stored reports (2):\n",
            "  ‚Ä¢ 2025_R1: Australian Grand Prix\n",
            "  ‚Ä¢ 2025_R8: Monaco Grand Prix\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'race_id': '2025_R1',\n",
              "  'gp_name': 'Australian Grand Prix',\n",
              "  'timestamp': '2025-11-25T09:25:56.412506'},\n",
              " {'race_id': '2025_R8',\n",
              "  'gp_name': 'Monaco Grand Prix',\n",
              "  'timestamp': '2025-11-25T09:27:51.198281'}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_reports()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
