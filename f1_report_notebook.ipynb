{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# F1 Race Report Generator\n",
        "\n",
        "Two-agent system with memory:\n",
        "- **Agent 1**: Data Collection (FastF1)\n",
        "- **Agent 2**: Report Generation (Gemini)\n",
        "- **Memory**: Store and retrieve race reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (python-dotenv only needed for local development)\n",
        "%pip install -q google-cloud-aiplatform==1.75.0 google-adk==0.1.5 fastf1==3.4.5 pandas==2.2.3 nest-asyncio==1.6.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Imports & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Any\n",
        "import pandas as pd\n",
        "import fastf1\n",
        "import vertexai\n",
        "import nest_asyncio\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "\n",
        "# Configuration - Supports both Kaggle and local environments\n",
        "# For Kaggle: Use Kaggle Secrets (see KAGGLE_SUBMISSION.md)\n",
        "# For local: Use .env file or environment variables\n",
        "\n",
        "# Try to load from Kaggle Secrets (if running in Kaggle)\n",
        "try:\n",
        "    from kaggle_secrets import UserSecretsClient\n",
        "    user_secrets = UserSecretsClient()\n",
        "    gcp_creds = user_secrets.get_secret(\"GCP_SERVICE_ACCOUNT\")\n",
        "    \n",
        "    # Write credentials to file for Vertex AI\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/tmp/gcp_credentials.json'\n",
        "    with open('/tmp/gcp_credentials.json', 'w') as f:\n",
        "        f.write(gcp_creds)\n",
        "    print(\"‚úì Loaded GCP credentials from Kaggle Secrets\")\n",
        "except:\n",
        "    # Fallback: Try local .env file or environment variables\n",
        "    try:\n",
        "        from dotenv import load_dotenv\n",
        "        load_dotenv()\n",
        "        print(\"‚úì Loaded configuration from .env file\")\n",
        "    except:\n",
        "        print(\"‚Ñπ Using default configuration (set GCP_PROJECT_ID and GCP_LOCATION if needed)\")\n",
        "\n",
        "# Project configuration\n",
        "PROJECT_ID = os.getenv('GCP_PROJECT_ID', 'gen-lang-client-0467867580')\n",
        "LOCATION = os.getenv('GCP_LOCATION', 'us-central1')\n",
        "MODEL_NAME = 'gemini-2.5-flash'\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "nest_asyncio.apply()\n",
        "fastf1.Cache.enable_cache('f1_cache')\n",
        "\n",
        "print(f\"‚úì Environment configured\")\n",
        "print(f\"  Project: {PROJECT_ID}\")\n",
        "print(f\"  Location: {LOCATION}\")\n",
        "print(f\"  Model: {MODEL_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Agent Engine Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Vertex AI Agent Engine for Memory Bank\n",
        "client = vertexai.Client(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Try to get existing agent engine or create new one\n",
        "try:\n",
        "    # List existing agent engines\n",
        "    agent_engines = list(client.agent_engines.list())\n",
        "    if agent_engines:\n",
        "        agent_engine = agent_engines[0]\n",
        "        print(f\"Using existing Agent Engine: {agent_engine.api_resource.name}\")\n",
        "    else:\n",
        "        # Create new agent engine\n",
        "        agent_engine = client.agent_engines.create()\n",
        "        print(f\"Created new Agent Engine: {agent_engine.api_resource.name}\")\n",
        "    \n",
        "    agent_engine_id = agent_engine.api_resource.name.split(\"/\")[-1]\n",
        "    print(f\"Engine ID: {agent_engine_id}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing Agent Engine: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Memory Service (Vertex AI Memory Bank)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from google.adk.memory import VertexAiMemoryBankService\n",
        "\n",
        "class MemoryService:\n",
        "    \"\"\"Persistent storage for race reports using Vertex AI Memory Bank + local backup.\"\"\"\n",
        "    \n",
        "    def __init__(self, project: str, location: str, agent_engine_id: str, backup_file: str = \"f1_reports_backup.json\"):\n",
        "        self._service = VertexAiMemoryBankService(\n",
        "            project=project,\n",
        "            location=location,\n",
        "            agent_engine_id=agent_engine_id\n",
        "        )\n",
        "        self._cache = {}  # Local cache for quick access\n",
        "        self._backup_file = backup_file\n",
        "        self._load_from_backup()  # Load from local backup first\n",
        "    \n",
        "    def _load_from_backup(self):\n",
        "        \"\"\"Load reports from local JSON backup file.\"\"\"\n",
        "        try:\n",
        "            if os.path.exists(self._backup_file):\n",
        "                with open(self._backup_file, 'r', encoding='utf-8') as f:\n",
        "                    self._cache = json.load(f)\n",
        "                print(f\"Loaded {len(self._cache)} report(s) from local backup\")\n",
        "            else:\n",
        "                print(\"No local backup found, starting fresh\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading backup: {e}\")\n",
        "    \n",
        "    def _save_to_backup(self):\n",
        "        \"\"\"Save reports to local JSON backup file.\"\"\"\n",
        "        try:\n",
        "            with open(self._backup_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(self._cache, f, indent=2, ensure_ascii=False)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving backup: {e}\")\n",
        "    \n",
        "    def add_session_to_memory(self, race_id: str, report_data: Dict[str, Any]) -> None:\n",
        "        \"\"\"Store a race report in Memory Bank and local backup.\"\"\"\n",
        "        try:\n",
        "            timestamp = datetime.now().isoformat()\n",
        "            entry = {\n",
        "                \"data\": report_data,\n",
        "                \"timestamp\": timestamp\n",
        "            }\n",
        "            \n",
        "            # Store in local cache\n",
        "            self._cache[race_id] = entry\n",
        "            \n",
        "            # Save to local backup file immediately\n",
        "            self._save_to_backup()\n",
        "            \n",
        "            # Store in Memory Bank (async operation wrapped in sync)\n",
        "            loop = asyncio.get_event_loop()\n",
        "            if loop.is_running():\n",
        "                asyncio.ensure_future(self._async_add_session(race_id, entry))\n",
        "            else:\n",
        "                loop.run_until_complete(self._async_add_session(race_id, entry))\n",
        "        except Exception as e:\n",
        "            print(f\"Error storing in Memory Bank: {e}\")\n",
        "            raise\n",
        "    \n",
        "    async def _async_add_session(self, race_id: str, entry: Dict[str, Any]):\n",
        "        \"\"\"Async helper to add session to Memory Bank.\"\"\"\n",
        "        # Create a session object that Memory Bank expects\n",
        "        from google.adk.sessions import Session\n",
        "        session = Session(\n",
        "            session_id=race_id,\n",
        "            user_id=\"f1_report_system\",\n",
        "            metadata=entry\n",
        "        )\n",
        "        await self._service.add_session_to_memory(session)\n",
        "    \n",
        "    def _search_local_cache(self, query: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Search stored reports in local cache by race_id or GP name.\"\"\"\n",
        "        results = []\n",
        "        query_lower = query.lower()\n",
        "        \n",
        "        for race_id, entry in self._cache.items():\n",
        "            # Search in race_id and GP name\n",
        "            gp_name = entry['data'].get('race_data', {}).get('gp_info', {}).get('name', '')\n",
        "            if query_lower in race_id.lower() or query_lower in gp_name.lower():\n",
        "                results.append({\n",
        "                    \"race_id\": race_id,\n",
        "                    \"gp_name\": gp_name,\n",
        "                    \"timestamp\": entry['timestamp']\n",
        "                })\n",
        "        \n",
        "        return results\n",
        "\n",
        "    async def _async_search_memory_vertex(self, query: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Async helper to search Vertex AI Memory Bank and map results to local cache entries.\"\"\"\n",
        "        try:\n",
        "            # Search with required parameters\n",
        "            response = await self._service.search_memory(\n",
        "                query=query,\n",
        "                app_name=\"f1_report_system\",\n",
        "                user_id=\"f1_report_system\"\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Vertex AI Memory Bank search error: {e}\")\n",
        "            return []\n",
        "        \n",
        "        results = []\n",
        "        memories = getattr(response, \"memories\", None) or getattr(response, \"Memories\", None) or []\n",
        "        for mem in memories:\n",
        "            # Try to get a session_id / race_id from the memory result\n",
        "            race_id = getattr(mem, \"session_id\", None)\n",
        "            entry = None\n",
        "\n",
        "            # Some implementations may nest a Session object\n",
        "            if hasattr(mem, \"session\"):\n",
        "                session_obj = getattr(mem, \"session\")\n",
        "                if session_obj is not None:\n",
        "                    race_id = race_id or getattr(session_obj, \"session_id\", None)\n",
        "                    metadata = getattr(session_obj, \"metadata\", None)\n",
        "                    if isinstance(metadata, dict):\n",
        "                        entry = metadata\n",
        "\n",
        "            # Fallback: some implementations may expose metadata / data directly\n",
        "            if entry is None:\n",
        "                metadata = getattr(mem, \"metadata\", None)\n",
        "                if isinstance(metadata, dict):\n",
        "                    entry = metadata\n",
        "\n",
        "            if not race_id:\n",
        "                # Without a race_id we can't map cleanly; skip this memory\n",
        "                continue\n",
        "\n",
        "            # Prefer our local cache copy when available\n",
        "            if race_id in self._cache:\n",
        "                entry = self._cache[race_id]\n",
        "\n",
        "            if not entry:\n",
        "                continue\n",
        "\n",
        "            # Keep cache up to date if we learned this entry from Vertex\n",
        "            if race_id not in self._cache:\n",
        "                self._cache[race_id] = entry\n",
        "\n",
        "            gp_name = entry['data'].get('race_data', {}).get('gp_info', {}).get('name', '')\n",
        "            results.append({\n",
        "                \"race_id\": race_id,\n",
        "                \"gp_name\": gp_name,\n",
        "                \"timestamp\": entry['timestamp']\n",
        "            })\n",
        "        \n",
        "        return results\n",
        "\n",
        "    def search_memory(self, query: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Search stored reports, preferring Vertex AI Memory Bank and falling back to local cache.\"\"\"\n",
        "        # Try Vertex AI Memory Bank first\n",
        "        try:\n",
        "            try:\n",
        "                loop = asyncio.get_event_loop()\n",
        "            except RuntimeError:\n",
        "                loop = asyncio.new_event_loop()\n",
        "                asyncio.set_event_loop(loop)\n",
        "\n",
        "            vertex_results = loop.run_until_complete(self._async_search_memory_vertex(query))\n",
        "            if vertex_results:\n",
        "                return vertex_results\n",
        "        except Exception as e:\n",
        "            print(f\"Vertex search failed, using local cache: {e}\")\n",
        "        \n",
        "        # Fallback: local cache search (previous behavior)\n",
        "        return self._search_local_cache(query)\n",
        "    \n",
        "    def get_report(self, race_id: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Retrieve a specific report.\"\"\"\n",
        "        return self._cache.get(race_id)\n",
        "    \n",
        "    def list_all(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"List all stored reports.\"\"\"\n",
        "        return [{\n",
        "            \"race_id\": race_id,\n",
        "            \"gp_name\": entry['data'].get('race_data', {}).get('gp_info', {}).get('name', 'Unknown'),\n",
        "            \"timestamp\": entry['timestamp']\n",
        "        } for race_id, entry in self._cache.items()]\n",
        "\n",
        "# Initialize memory service with Vertex AI Memory Bank + local backup\n",
        "memory = MemoryService(\n",
        "    project=PROJECT_ID,\n",
        "    location=LOCATION,\n",
        "    agent_engine_id=agent_engine_id\n",
        ")\n",
        "print(\"Memory service initialized (Vertex AI Memory Bank + local backup)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# F1 Calendar (2024/2025 - compatible structure)\n",
        "F1_2025_CALENDAR = {\n",
        "    1: {\"name\": \"Bahrain Grand Prix\", \"circuit\": \"Bahrain International Circuit\"},\n",
        "    2: {\"name\": \"Saudi Arabian Grand Prix\", \"circuit\": \"Jeddah Corniche Circuit\"},\n",
        "    3: {\"name\": \"Australian Grand Prix\", \"circuit\": \"Albert Park Circuit\"},\n",
        "    4: {\"name\": \"Japanese Grand Prix\", \"circuit\": \"Suzuka International Racing Course\"},\n",
        "    5: {\"name\": \"Chinese Grand Prix\", \"circuit\": \"Shanghai International Circuit\"},\n",
        "    6: {\"name\": \"Miami Grand Prix\", \"circuit\": \"Miami International Autodrome\"},\n",
        "    7: {\"name\": \"Emilia Romagna Grand Prix\", \"circuit\": \"Autodromo Enzo e Dino Ferrari\"},\n",
        "    8: {\"name\": \"Monaco Grand Prix\", \"circuit\": \"Circuit de Monaco\"},\n",
        "    9: {\"name\": \"Spanish Grand Prix\", \"circuit\": \"Circuit de Barcelona-Catalunya\"},\n",
        "    10: {\"name\": \"Canadian Grand Prix\", \"circuit\": \"Circuit Gilles Villeneuve\"},\n",
        "    11: {\"name\": \"Austrian Grand Prix\", \"circuit\": \"Red Bull Ring\"},\n",
        "    12: {\"name\": \"British Grand Prix\", \"circuit\": \"Silverstone Circuit\"},\n",
        "    13: {\"name\": \"Belgian Grand Prix\", \"circuit\": \"Circuit de Spa-Francorchamps\"},\n",
        "    14: {\"name\": \"Hungarian Grand Prix\", \"circuit\": \"Hungaroring\"},\n",
        "    15: {\"name\": \"Dutch Grand Prix\", \"circuit\": \"Circuit Zandvoort\"},\n",
        "    16: {\"name\": \"Italian Grand Prix\", \"circuit\": \"Autodromo Nazionale di Monza\"},\n",
        "    17: {\"name\": \"Azerbaijan Grand Prix\", \"circuit\": \"Baku City Circuit\"},\n",
        "    18: {\"name\": \"Singapore Grand Prix\", \"circuit\": \"Marina Bay Street Circuit\"},\n",
        "    19: {\"name\": \"United States Grand Prix\", \"circuit\": \"Circuit of the Americas\"},\n",
        "    20: {\"name\": \"Mexico City Grand Prix\", \"circuit\": \"Aut√≥dromo Hermanos Rodr√≠guez\"},\n",
        "    21: {\"name\": \"S√£o Paulo Grand Prix\", \"circuit\": \"Aut√≥dromo Jos√© Carlos Pace\"},\n",
        "    22: {\"name\": \"Las Vegas Grand Prix\", \"circuit\": \"Las Vegas Street Circuit\"},\n",
        "    23: {\"name\": \"Qatar Grand Prix\", \"circuit\": \"Lusail International Circuit\"},\n",
        "    24: {\"name\": \"Abu Dhabi Grand Prix\", \"circuit\": \"Yas Marina Circuit\"}\n",
        "}\n",
        "\n",
        "print(f\"Calendar loaded: {len(F1_2025_CALENDAR)} races\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Agent 1: Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DataCollectionAgent:\n",
        "    \"\"\"Validates input and collects F1 race data.\"\"\"\n",
        "    \n",
        "    def __init__(self, calendar: Dict[int, Dict[str, str]], year: int = 2025):\n",
        "        self.calendar = calendar\n",
        "        self.year = year\n",
        "    \n",
        "    def validate_input(self, user_input: str) -> Optional[int]:\n",
        "        \"\"\"Validate and convert user input to round number.\"\"\"\n",
        "        user_input = user_input.strip()\n",
        "        \n",
        "        # Try parsing as round number\n",
        "        try:\n",
        "            round_num = int(user_input)\n",
        "            return round_num if round_num in self.calendar else None\n",
        "        except ValueError:\n",
        "            pass\n",
        "        \n",
        "        # Try matching GP name\n",
        "        user_lower = user_input.lower()\n",
        "        for round_num, info in self.calendar.items():\n",
        "            if user_lower in info['name'].lower():\n",
        "                return round_num\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def collect_race_data(self, round_num: int, year: Optional[int] = None) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Collect comprehensive race data.\"\"\"\n",
        "        if year is None:\n",
        "            year = self.year\n",
        "            \n",
        "        try:\n",
        "            print(f\"Collecting data for Round {round_num} ({year})...\")\n",
        "            \n",
        "            # Get event and session\n",
        "            event = fastf1.get_event(year, round_num)\n",
        "            session = fastf1.get_session(year, round_num, \"R\")\n",
        "            session.load()\n",
        "            \n",
        "            results = session.results\n",
        "            \n",
        "            # Process results\n",
        "            drivers_results = []\n",
        "            for idx, row in results.iterrows():\n",
        "                # Try multiple position fields (fallback chain) with safe conversion\n",
        "                position = None\n",
        "                try:\n",
        "                    if pd.notna(row.get('Position')) and str(row.get('Position', '')).strip():\n",
        "                        position = int(row['Position'])\n",
        "                except (ValueError, TypeError):\n",
        "                    pass\n",
        "                \n",
        "                if position is None:\n",
        "                    try:\n",
        "                        if pd.notna(row.get('ClassifiedPosition')) and str(row.get('ClassifiedPosition', '')).strip():\n",
        "                            position = int(row['ClassifiedPosition'])\n",
        "                    except (ValueError, TypeError):\n",
        "                        pass\n",
        "                \n",
        "                if position is None and 'Status' in row and str(row['Status']) == 'Finished':\n",
        "                    # For finished drivers without position, use order in dataframe (usually sorted)\n",
        "                    position = len([d for d in drivers_results if d['position'] is not None]) + 1\n",
        "                \n",
        "                # Handle GridPosition safely (might be empty string or NaN)\n",
        "                grid_pos = None\n",
        "                try:\n",
        "                    if pd.notna(row['GridPosition']) and str(row['GridPosition']).strip():\n",
        "                        grid_pos = int(row['GridPosition'])\n",
        "                except (ValueError, TypeError):\n",
        "                    pass\n",
        "                \n",
        "                drivers_results.append({\n",
        "                    \"position\": position,\n",
        "                    \"full_name\": str(row['FullName']) if pd.notna(row['FullName']) else None,\n",
        "                    \"team\": str(row['TeamName']) if pd.notna(row['TeamName']) else None,\n",
        "                    \"grid_position\": grid_pos,\n",
        "                    \"time\": str(row['Time']) if pd.notna(row['Time']) else None,\n",
        "                    \"points\": float(row['Points']) if pd.notna(row['Points']) else 0.0,\n",
        "                })\n",
        "            \n",
        "            # If no positions were found, assign based on results order (FastF1 usually sorts by finish)\n",
        "            if all(r['position'] is None for r in drivers_results):\n",
        "                print(\"No position data from Ergast, using results order\")\n",
        "                for idx, driver in enumerate(drivers_results):\n",
        "                    driver['position'] = idx + 1\n",
        "            \n",
        "            # Get podium and key stats\n",
        "            podium = sorted([r for r in drivers_results if r['position'] in [1, 2, 3]], key=lambda x: x['position'])\n",
        "            \n",
        "            # Compile data\n",
        "            race_data = {\n",
        "                \"race_id\": f\"{year}_R{round_num}\",\n",
        "                \"year\": year,\n",
        "                \"round\": round_num,\n",
        "                \"gp_info\": {\n",
        "                    \"name\": event.EventName,\n",
        "                    \"country\": event.Country,\n",
        "                    \"circuit\": self.calendar[round_num]['circuit'],\n",
        "                },\n",
        "                \"podium\": podium,\n",
        "                \"final_results\": [r for r in drivers_results if r['position'] is not None]\n",
        "            }\n",
        "            \n",
        "            print(f\"Data collected: {event.EventName} ({year})\")\n",
        "            print(f\"Podium finishers: {len(podium)}\")\n",
        "            return race_data\n",
        "            \n",
        "        except Exception as e:\n",
        "            # Fallback to previous year if current year fails\n",
        "            if year >= 2024 and year == self.year:\n",
        "                print(f\"{year} data unavailable, trying {year-1}...\")\n",
        "                return self.collect_race_data(round_num, year=year-1)\n",
        "            print(f\"Error: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def run(self, user_input: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Main execution.\"\"\"\n",
        "        round_num = self.validate_input(user_input)\n",
        "        if not round_num:\n",
        "            print(f\"Invalid input: '{user_input}'\")\n",
        "            return None\n",
        "        return self.collect_race_data(round_num)\n",
        "\n",
        "agent1 = DataCollectionAgent(F1_2025_CALENDAR)\n",
        "print(\"Agent 1 initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Agent 2: Report Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReportGenerationAgent:\n",
        "    \"\"\"Generates social media reports from race data.\"\"\"\n",
        "    \n",
        "    def __init__(self, model_name: str = 'gemini-2.5-flash'):\n",
        "        self.model = GenerativeModel(model_name)\n",
        "    \n",
        "    def generate_report(self, race_data: Dict[str, Any]) -> Optional[str]:\n",
        "        \"\"\"Generate social media post.\"\"\"\n",
        "        try:\n",
        "            gp_info = race_data['gp_info']\n",
        "            podium = race_data['podium']\n",
        "            \n",
        "            # Validate podium data\n",
        "            if len(podium) < 3:\n",
        "                print(f\"Incomplete podium data: only {len(podium)} finisher(s)\")\n",
        "                return None\n",
        "            \n",
        "            print(f\"Generating report for {gp_info['name']}...\")\n",
        "            \n",
        "            prompt = f\"\"\"Create an Instagram post for this F1 race:\n",
        "\n",
        "RACE: {gp_info['name']} ({race_data['year']})\n",
        "CIRCUIT: {gp_info['circuit']}\n",
        "\n",
        "PODIUM:\n",
        "1st: {podium[0]['full_name']} ({podium[0]['team']}) - Started P{podium[0]['grid_position']}\n",
        "2nd: {podium[1]['full_name']} ({podium[1]['team']}) - Started P{podium[1]['grid_position']}\n",
        "3rd: {podium[2]['full_name']} ({podium[2]['team']}) - Started P{podium[2]['grid_position']}\n",
        "\n",
        "Write an engaging social media post that tells the race story and highlights the key moments. Don't generate images, just text.\"\"\"\n",
        "\n",
        "            response = self.model.generate_content(\n",
        "                prompt,\n",
        "                generation_config={\n",
        "                    \"max_output_tokens\": 2048,\n",
        "                    \"temperature\": 0.5,\n",
        "                }\n",
        "            )\n",
        "            \n",
        "            print(f\"Report generated ({len(response.text)} chars)\")\n",
        "            return response.text.strip()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def run(self, race_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Main execution.\"\"\"\n",
        "        if not race_data:\n",
        "            return None\n",
        "        \n",
        "        social_media_post = self.generate_report(race_data)\n",
        "        if not social_media_post:\n",
        "            return None\n",
        "        \n",
        "        return {\n",
        "            \"race_id\": race_data['race_id'],\n",
        "            \"race_data\": race_data,\n",
        "            \"social_media_post\": social_media_post,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "agent2 = ReportGenerationAgent(MODEL_NAME)\n",
        "print(\"Agent 2 initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Workflow: Generate & Store Reports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_f1_report(race_input: str) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"Complete workflow: collect data ‚Üí generate report ‚Üí store in memory.\"\"\"\n",
        "    \n",
        "    # 1. Collect race data\n",
        "    race_data = agent1.run(race_input)\n",
        "    if not race_data:\n",
        "        return None\n",
        "    \n",
        "    # 2. Generate report\n",
        "    full_report = agent2.run(race_data)\n",
        "    if not full_report:\n",
        "        return None\n",
        "    \n",
        "    # 3. Store in memory (INGEST)\n",
        "    memory.add_session_to_memory(full_report['race_id'], full_report)\n",
        "    \n",
        "    # Display result\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SOCIAL MEDIA POST\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\n{full_report['social_media_post']}\\n\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Stored as: {full_report['race_id']}\")\n",
        "    \n",
        "    return full_report\n",
        "\n",
        "print(\"Workflow ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Memory Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Search memory (RETRIEVE)\n",
        "def search_reports(query: str):\n",
        "    \"\"\"Search stored reports.\"\"\"\n",
        "    results = memory.search_memory(query)\n",
        "    if results:\n",
        "        print(f\"Found {len(results)} report(s):\")\n",
        "        for r in results:\n",
        "            print(f\"  - {r['race_id']}: {r['gp_name']} ({r['timestamp']})\")\n",
        "    else:\n",
        "        print(f\"No reports found for '{query}'\")\n",
        "    return results\n",
        "\n",
        "# List all reports\n",
        "def list_reports():\n",
        "    \"\"\"List all stored reports.\"\"\"\n",
        "    reports = memory.list_all()\n",
        "    if reports:\n",
        "        print(f\"Stored reports ({len(reports)}):\")\n",
        "        for r in reports:\n",
        "            print(f\"  - {r['race_id']}: {r['gp_name']}\")\n",
        "    else:\n",
        "        print(\"No reports stored yet\")\n",
        "    return reports\n",
        "\n",
        "# Get specific report\n",
        "def get_report(race_id: str):\n",
        "    \"\"\"Retrieve a specific report.\"\"\"\n",
        "    report = memory.get_report(race_id)\n",
        "    if report:\n",
        "        print(f\"Retrieved: {race_id}\")\n",
        "        print(f\"GP: {report['data']['race_data']['gp_info']['name']}\")\n",
        "        print(f\"Stored: {report['timestamp']}\")\n",
        "        return report\n",
        "    else:\n",
        "        print(f\"Report '{race_id}' not found\")\n",
        "        return None\n",
        "\n",
        "print(\"Memory operations ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Search & Retrieve from Memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all stored reports\n",
        "list_reports()\n",
        "\n",
        "# Search for specific reports\n",
        "search_reports(\"Bahrain\")\n",
        "\n",
        "# Retrieve a specific report\n",
        "report = get_report(\"2025_R1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search_reports(\"Australian Grand Prix\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive mode\n",
        "race_input = input(\"Enter race (round number or GP name): \")\n",
        "report = generate_f1_report(race_input)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Demonstration: Full System Workflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstration: Generate reports for multiple races\n",
        "print(\"=\"*70)\n",
        "print(\"F1 REPORT SYSTEM - DEMONSTRATION\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nThis demonstrates the complete two-agent system:\\n\")\n",
        "print(\"1. Agent 1: Data Collection (FastF1)\")\n",
        "print(\"2. Agent 2: Report Generation (Gemini 2.5 Flash)\")\n",
        "print(\"3. Memory: Persistent Storage (Vertex AI Memory Bank)\\n\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test with multiple races\n",
        "demo_races = [\"Monaco\", \"Saudi Arabia\", \"Japan\"]\n",
        "\n",
        "for i, race in enumerate(demo_races, 1):\n",
        "    print(f\"\\n[{i}/{len(demo_races)}] Processing: {race}\")\n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    report = generate_f1_report(race)\n",
        "    if report:\n",
        "        print(f\"‚úÖ Success! Report ID: {report['race_id']}\")\n",
        "        print(f\"üìä GP: {report['race_data']['gp_info']['name']}\")\n",
        "        print(f\"üìù Post length: {len(report['social_media_post'])} characters\")\n",
        "    else:\n",
        "        print(f\"‚ùå Failed to generate report for {race}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SYSTEM SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "all_reports = list_reports()\n",
        "print(f\"\\n‚úÖ Total reports stored: {len(all_reports)}\")\n",
        "print(f\"‚úÖ Memory system: Vertex AI Memory Bank + Local Backup\")\n",
        "print(f\"‚úÖ Agents: Data Collection + Report Generation\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_reports()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
